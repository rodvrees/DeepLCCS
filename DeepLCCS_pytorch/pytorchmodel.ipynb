{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_df = pd.read_csv('/home/robbe/DeepLCCS/data/peprec_CCS.csv')\n",
    "X_train = pickle.load(open('/home/robbe/DeepLCCS/data/X_train_full.pickle', 'rb'))\n",
    "global_feats_train = pickle.load(open('/home/robbe/DeepLCCS/data/global_feats_train_full.pickle', 'rb'))\n",
    "X_test = pickle.load(open('/home/robbe/DeepLCCS/data/X_test_full.pickle', 'rb'))\n",
    "global_feats_test = pickle.load(open('/home/robbe/DeepLCCS/data/global_feats_test_full.pickle', 'rb'))\n",
    "ccs_df_train = pickle.load(open('/home/robbe/DeepLCCS/data/ccs_df_train_full.pickle', 'rb'))\n",
    "ccs_df_test = pickle.load(open('/home/robbe/DeepLCCS/data/ccs_df_test_full.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(651338, 6, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(651338, 60, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train_reshaped = X_train.transpose(0, 2, 1)\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651338, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = ccs_df_train.loc[:, 'tr']\n",
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "y_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651338, 19)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (lstm): LSTM(6, 256, batch_first=True, bidirectional=True)\n",
      "  (global_dense): Sequential(\n",
      "    (0): Linear(in_features=19, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=528, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (lstm): LSTM(6, 256, batch_first=True, bidirectional=True)\n",
       "  (global_dense): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=528, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input1_size, input2_size, lstm_hidden_size, global_dense_hidden_size, concat_dense_hidden_size, output_size, num_layers, activation):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # Bidirectional LSTM layer\n",
    "        self.lstm = nn.LSTM(input1_size, lstm_hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "\n",
    "        # Dense network for input 2\n",
    "        self.global_dense = nn.Sequential(\n",
    "            nn.Linear(input2_size, global_dense_hidden_size),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        # Concatenated size for the fully connected layer\n",
    "        concat_size = 2 * lstm_hidden_size + global_dense_hidden_size\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(concat_size, concat_dense_hidden_size[0]),\n",
    "            activation,\n",
    "            nn.Linear(concat_dense_hidden_size[0], concat_dense_hidden_size[1]),\n",
    "            activation,\n",
    "            nn.Linear(concat_dense_hidden_size[1], output_size),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Input 1 through Bidirectional LSTM\n",
    "        lstm_output, _ = self.lstm(input1)\n",
    "\n",
    "        # Get the last output of the LSTM\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        # Input 2 through Dense Network\n",
    "        dense_output = self.global_dense(input2)\n",
    "\n",
    "        # Concatenate the outputs\n",
    "        concatenated = torch.cat((lstm_output, dense_output), dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(concatenated)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Define the parameters\n",
    "input1_size = 6\n",
    "input2_size = 19\n",
    "lstm_hidden_size = 256\n",
    "global_dense_hidden_size = 16\n",
    "concat_dense_hidden_size = [64, 32]\n",
    "output_size = 1  # Scalar value output\n",
    "num_layers = 1\n",
    "activation = nn.ReLU()  # You can adjust activation function here\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input1_size, input2_size, lstm_hidden_size, global_dense_hidden_size, concat_dense_hidden_size, output_size, num_layers, activation)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # You can adjust the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your training data (assuming you have it in numpy arrays)\n",
    "# Replace X_train_input1, X_train_input2, y_train with your actual training data\n",
    "X_train_input1 = torch.tensor(X_train_reshaped, dtype=torch.float32)  # Shape: (num_samples, sequence_length, input1_size)\n",
    "X_train_input2 = torch.tensor(global_feats_train, dtype=torch.float32)  # Shape: (num_samples, input2_size)\n",
    "y_train = torch.tensor(y_train_reshaped, dtype=torch.float32)         # Shape: (num_samples, output_size)\n",
    "X_train_input1 = X_train_input1.to(device)\n",
    "X_train_input2 = X_train_input2.to(device)\n",
    "y_train = y_train.to(device)\n",
    "# Split the data into training and validation sets\n",
    "X_train_input1, X_val_input1, X_train_input2, X_val_input2, y_train, y_val = train_test_split(\n",
    "    X_train_input1, X_train_input2, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorDatasets for training and validation\n",
    "train_dataset = TensorDataset(X_train_input1, X_train_input2, y_train)\n",
    "val_dataset = TensorDataset(X_val_input1, X_val_input2, y_val)\n",
    "\n",
    "# Define DataLoader for training and validation sets\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_error(targets, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the mean absolute error (MAE).\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(targets - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10):\n",
    "    mae_values = []\n",
    "    val_mae_values = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        for inputs1_batch, inputs2_batch, targets_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs1_batch, inputs2_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets_batch)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validate the model after each epoch\n",
    "        validation_loss = validate_model(model, criterion, valid_loader)\n",
    "        with torch.no_grad():\n",
    "            train_predictions = []\n",
    "            train_targets = []\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "            for inputs1_batch, inputs2_batch, targets_batch in train_loader:\n",
    "                outputs = model(inputs1_batch, inputs2_batch)\n",
    "                train_predictions.extend(outputs.cpu().numpy())\n",
    "                train_targets.extend(targets_batch.cpu().numpy())\n",
    "\n",
    "            for inputs1_batch, inputs2_batch, targets_batch in valid_loader:\n",
    "                outputs = model(inputs1_batch, inputs2_batch)\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(targets_batch.cpu().numpy())\n",
    "\n",
    "            mae = mean_absolute_error(np.array(train_targets), np.array(train_predictions))\n",
    "            mae_values.append(mae)\n",
    "            val_mae = mean_absolute_error(np.array(val_targets), np.array(val_predictions))\n",
    "            val_mae_values.append(val_mae)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]: Loss: {loss:.4f}, MAE: {mae:.4f}, Validation Loss: {validation_loss:.4f}, Validation MAE: {val_mae:.4f}')\n",
    "\n",
    "    print('Training finished!')\n",
    "\n",
    "\n",
    "def validate_model(model, criterion, valid_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs1_batch, inputs2_batch, targets_batch in valid_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs1_batch, inputs2_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, targets_batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: Loss: 1437.8615, MAE: 27.5497, Validation Loss: 1607.9731, Validation MAE: 27.7050\n",
      "Epoch [2/10]: Loss: 1223.6923, MAE: 26.5822, Validation Loss: 1480.8574, Validation MAE: 26.7169\n",
      "Epoch [3/10]: Loss: 1199.4352, MAE: 24.7058, Validation Loss: 1315.6968, Validation MAE: 24.8192\n",
      "Epoch [4/10]: Loss: 1071.8512, MAE: 22.3273, Validation Loss: 1070.1194, Validation MAE: 22.4132\n",
      "Epoch [5/10]: Loss: 809.8674, MAE: 17.8874, Validation Loss: 705.8277, Validation MAE: 17.9754\n",
      "Epoch [6/10]: Loss: 731.6390, MAE: 14.8015, Validation Loss: 468.2140, Validation MAE: 14.8728\n",
      "Epoch [7/10]: Loss: 463.9671, MAE: 13.4790, Validation Loss: 398.5749, Validation MAE: 13.5530\n",
      "Epoch [8/10]: Loss: 493.9843, MAE: 13.1905, Validation Loss: 383.2412, Validation MAE: 13.2620\n",
      "Epoch [9/10]: Loss: 485.4931, MAE: 13.2293, Validation Loss: 384.8172, Validation MAE: 13.2911\n",
      "Epoch [10/10]: Loss: 332.3246, MAE: 12.7505, Validation Loss: 367.5258, Validation MAE: 12.8340\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Assuming `model` is your trained PyTorch model and `val_loader` is your DataLoader for validation data\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# List to store validation predictions\n",
    "val_predictions = []\n",
    "\n",
    "# Iterate over the validation dataset\n",
    "with torch.no_grad():\n",
    "    for inputs1, inputs2, targets in val_loader:\n",
    "        # Move inputs and targets to the same device as the model\n",
    "        inputs1 = inputs1.to(device)\n",
    "        inputs2 = inputs2.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs1, inputs2)\n",
    "\n",
    "        # Convert predictions to CPU and append to list\n",
    "        val_predictions.extend(outputs.cpu().numpy())  # Assuming your targets are numpy arrays\n",
    "\n",
    "# Convert the list of predictions to a numpy array\n",
    "val_predictions = np.array(val_predictions)\n",
    "\n",
    "# Now you can use val_predictions for further analysis or visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[370.2365 ],\n",
       "       [496.42847],\n",
       "       [457.5915 ],\n",
       "       ...,\n",
       "       [509.1925 ],\n",
       "       [384.73877],\n",
       "       [555.34143]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[363.9794],\n",
       "        [505.2887],\n",
       "        [454.0214],\n",
       "        ...,\n",
       "        [541.1950],\n",
       "        [388.6454],\n",
       "        [516.8959]], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "global_feats_train = pickle.load(\n",
    "        open(\"/home/robbe/DeepLCCS/data/global_feats_train_full-onlyDeepLCtrainset.pickle\", \"rb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651338, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 216\n",
      "Combinations: [(32, 32, 32), (32, 32, 64), (32, 32, 128), (32, 32, 256), (32, 32, 512), (32, 32, 1024), (32, 64, 32), (32, 64, 64), (32, 64, 128), (32, 64, 256), (32, 64, 512), (32, 64, 1024), (32, 128, 32), (32, 128, 64), (32, 128, 128), (32, 128, 256), (32, 128, 512), (32, 128, 1024), (32, 256, 32), (32, 256, 64), (32, 256, 128), (32, 256, 256), (32, 256, 512), (32, 256, 1024), (32, 512, 32), (32, 512, 64), (32, 512, 128), (32, 512, 256), (32, 512, 512), (32, 512, 1024), (32, 1024, 32), (32, 1024, 64), (32, 1024, 128), (32, 1024, 256), (32, 1024, 512), (32, 1024, 1024), (64, 32, 32), (64, 32, 64), (64, 32, 128), (64, 32, 256), (64, 32, 512), (64, 32, 1024), (64, 64, 32), (64, 64, 64), (64, 64, 128), (64, 64, 256), (64, 64, 512), (64, 64, 1024), (64, 128, 32), (64, 128, 64), (64, 128, 128), (64, 128, 256), (64, 128, 512), (64, 128, 1024), (64, 256, 32), (64, 256, 64), (64, 256, 128), (64, 256, 256), (64, 256, 512), (64, 256, 1024), (64, 512, 32), (64, 512, 64), (64, 512, 128), (64, 512, 256), (64, 512, 512), (64, 512, 1024), (64, 1024, 32), (64, 1024, 64), (64, 1024, 128), (64, 1024, 256), (64, 1024, 512), (64, 1024, 1024), (128, 32, 32), (128, 32, 64), (128, 32, 128), (128, 32, 256), (128, 32, 512), (128, 32, 1024), (128, 64, 32), (128, 64, 64), (128, 64, 128), (128, 64, 256), (128, 64, 512), (128, 64, 1024), (128, 128, 32), (128, 128, 64), (128, 128, 128), (128, 128, 256), (128, 128, 512), (128, 128, 1024), (128, 256, 32), (128, 256, 64), (128, 256, 128), (128, 256, 256), (128, 256, 512), (128, 256, 1024), (128, 512, 32), (128, 512, 64), (128, 512, 128), (128, 512, 256), (128, 512, 512), (128, 512, 1024), (128, 1024, 32), (128, 1024, 64), (128, 1024, 128), (128, 1024, 256), (128, 1024, 512), (128, 1024, 1024), (256, 32, 32), (256, 32, 64), (256, 32, 128), (256, 32, 256), (256, 32, 512), (256, 32, 1024), (256, 64, 32), (256, 64, 64), (256, 64, 128), (256, 64, 256), (256, 64, 512), (256, 64, 1024), (256, 128, 32), (256, 128, 64), (256, 128, 128), (256, 128, 256), (256, 128, 512), (256, 128, 1024), (256, 256, 32), (256, 256, 64), (256, 256, 128), (256, 256, 256), (256, 256, 512), (256, 256, 1024), (256, 512, 32), (256, 512, 64), (256, 512, 128), (256, 512, 256), (256, 512, 512), (256, 512, 1024), (256, 1024, 32), (256, 1024, 64), (256, 1024, 128), (256, 1024, 256), (256, 1024, 512), (256, 1024, 1024), (512, 32, 32), (512, 32, 64), (512, 32, 128), (512, 32, 256), (512, 32, 512), (512, 32, 1024), (512, 64, 32), (512, 64, 64), (512, 64, 128), (512, 64, 256), (512, 64, 512), (512, 64, 1024), (512, 128, 32), (512, 128, 64), (512, 128, 128), (512, 128, 256), (512, 128, 512), (512, 128, 1024), (512, 256, 32), (512, 256, 64), (512, 256, 128), (512, 256, 256), (512, 256, 512), (512, 256, 1024), (512, 512, 32), (512, 512, 64), (512, 512, 128), (512, 512, 256), (512, 512, 512), (512, 512, 1024), (512, 1024, 32), (512, 1024, 64), (512, 1024, 128), (512, 1024, 256), (512, 1024, 512), (512, 1024, 1024), (1024, 32, 32), (1024, 32, 64), (1024, 32, 128), (1024, 32, 256), (1024, 32, 512), (1024, 32, 1024), (1024, 64, 32), (1024, 64, 64), (1024, 64, 128), (1024, 64, 256), (1024, 64, 512), (1024, 64, 1024), (1024, 128, 32), (1024, 128, 64), (1024, 128, 128), (1024, 128, 256), (1024, 128, 512), (1024, 128, 1024), (1024, 256, 32), (1024, 256, 64), (1024, 256, 128), (1024, 256, 256), (1024, 256, 512), (1024, 256, 1024), (1024, 512, 32), (1024, 512, 64), (1024, 512, 128), (1024, 512, 256), (1024, 512, 512), (1024, 512, 1024), (1024, 1024, 32), (1024, 1024, 64), (1024, 1024, 128), (1024, 1024, 256), (1024, 1024, 512), (1024, 1024, 1024)]\n",
      "[32, 32, 32]\n",
      "[32, 32, 64]\n",
      "[32, 32, 128]\n",
      "[32, 32, 256]\n",
      "[32, 32, 512]\n",
      "[32, 32, 1024]\n",
      "[32, 64, 32]\n",
      "[32, 64, 64]\n",
      "[32, 64, 128]\n",
      "[32, 64, 256]\n",
      "[32, 64, 512]\n",
      "[32, 64, 1024]\n",
      "[32, 128, 32]\n",
      "[32, 128, 64]\n",
      "[32, 128, 128]\n",
      "[32, 128, 256]\n",
      "[32, 128, 512]\n",
      "[32, 128, 1024]\n",
      "[32, 256, 32]\n",
      "[32, 256, 64]\n",
      "[32, 256, 128]\n",
      "[32, 256, 256]\n",
      "[32, 256, 512]\n",
      "[32, 256, 1024]\n",
      "[32, 512, 32]\n",
      "[32, 512, 64]\n",
      "[32, 512, 128]\n",
      "[32, 512, 256]\n",
      "[32, 512, 512]\n",
      "[32, 512, 1024]\n",
      "[32, 1024, 32]\n",
      "[32, 1024, 64]\n",
      "[32, 1024, 128]\n",
      "[32, 1024, 256]\n",
      "[32, 1024, 512]\n",
      "[32, 1024, 1024]\n",
      "[64, 32, 32]\n",
      "[64, 32, 64]\n",
      "[64, 32, 128]\n",
      "[64, 32, 256]\n",
      "[64, 32, 512]\n",
      "[64, 32, 1024]\n",
      "[64, 64, 32]\n",
      "[64, 64, 64]\n",
      "[64, 64, 128]\n",
      "[64, 64, 256]\n",
      "[64, 64, 512]\n",
      "[64, 64, 1024]\n",
      "[64, 128, 32]\n",
      "[64, 128, 64]\n",
      "[64, 128, 128]\n",
      "[64, 128, 256]\n",
      "[64, 128, 512]\n",
      "[64, 128, 1024]\n",
      "[64, 256, 32]\n",
      "[64, 256, 64]\n",
      "[64, 256, 128]\n",
      "[64, 256, 256]\n",
      "[64, 256, 512]\n",
      "[64, 256, 1024]\n",
      "[64, 512, 32]\n",
      "[64, 512, 64]\n",
      "[64, 512, 128]\n",
      "[64, 512, 256]\n",
      "[64, 512, 512]\n",
      "[64, 512, 1024]\n",
      "[64, 1024, 32]\n",
      "[64, 1024, 64]\n",
      "[64, 1024, 128]\n",
      "[64, 1024, 256]\n",
      "[64, 1024, 512]\n",
      "[64, 1024, 1024]\n",
      "[128, 32, 32]\n",
      "[128, 32, 64]\n",
      "[128, 32, 128]\n",
      "[128, 32, 256]\n",
      "[128, 32, 512]\n",
      "[128, 32, 1024]\n",
      "[128, 64, 32]\n",
      "[128, 64, 64]\n",
      "[128, 64, 128]\n",
      "[128, 64, 256]\n",
      "[128, 64, 512]\n",
      "[128, 64, 1024]\n",
      "[128, 128, 32]\n",
      "[128, 128, 64]\n",
      "[128, 128, 128]\n",
      "[128, 128, 256]\n",
      "[128, 128, 512]\n",
      "[128, 128, 1024]\n",
      "[128, 256, 32]\n",
      "[128, 256, 64]\n",
      "[128, 256, 128]\n",
      "[128, 256, 256]\n",
      "[128, 256, 512]\n",
      "[128, 256, 1024]\n",
      "[128, 512, 32]\n",
      "[128, 512, 64]\n",
      "[128, 512, 128]\n",
      "[128, 512, 256]\n",
      "[128, 512, 512]\n",
      "[128, 512, 1024]\n",
      "[128, 1024, 32]\n",
      "[128, 1024, 64]\n",
      "[128, 1024, 128]\n",
      "[128, 1024, 256]\n",
      "[128, 1024, 512]\n",
      "[128, 1024, 1024]\n",
      "[256, 32, 32]\n",
      "[256, 32, 64]\n",
      "[256, 32, 128]\n",
      "[256, 32, 256]\n",
      "[256, 32, 512]\n",
      "[256, 32, 1024]\n",
      "[256, 64, 32]\n",
      "[256, 64, 64]\n",
      "[256, 64, 128]\n",
      "[256, 64, 256]\n",
      "[256, 64, 512]\n",
      "[256, 64, 1024]\n",
      "[256, 128, 32]\n",
      "[256, 128, 64]\n",
      "[256, 128, 128]\n",
      "[256, 128, 256]\n",
      "[256, 128, 512]\n",
      "[256, 128, 1024]\n",
      "[256, 256, 32]\n",
      "[256, 256, 64]\n",
      "[256, 256, 128]\n",
      "[256, 256, 256]\n",
      "[256, 256, 512]\n",
      "[256, 256, 1024]\n",
      "[256, 512, 32]\n",
      "[256, 512, 64]\n",
      "[256, 512, 128]\n",
      "[256, 512, 256]\n",
      "[256, 512, 512]\n",
      "[256, 512, 1024]\n",
      "[256, 1024, 32]\n",
      "[256, 1024, 64]\n",
      "[256, 1024, 128]\n",
      "[256, 1024, 256]\n",
      "[256, 1024, 512]\n",
      "[256, 1024, 1024]\n",
      "[512, 32, 32]\n",
      "[512, 32, 64]\n",
      "[512, 32, 128]\n",
      "[512, 32, 256]\n",
      "[512, 32, 512]\n",
      "[512, 32, 1024]\n",
      "[512, 64, 32]\n",
      "[512, 64, 64]\n",
      "[512, 64, 128]\n",
      "[512, 64, 256]\n",
      "[512, 64, 512]\n",
      "[512, 64, 1024]\n",
      "[512, 128, 32]\n",
      "[512, 128, 64]\n",
      "[512, 128, 128]\n",
      "[512, 128, 256]\n",
      "[512, 128, 512]\n",
      "[512, 128, 1024]\n",
      "[512, 256, 32]\n",
      "[512, 256, 64]\n",
      "[512, 256, 128]\n",
      "[512, 256, 256]\n",
      "[512, 256, 512]\n",
      "[512, 256, 1024]\n",
      "[512, 512, 32]\n",
      "[512, 512, 64]\n",
      "[512, 512, 128]\n",
      "[512, 512, 256]\n",
      "[512, 512, 512]\n",
      "[512, 512, 1024]\n",
      "[512, 1024, 32]\n",
      "[512, 1024, 64]\n",
      "[512, 1024, 128]\n",
      "[512, 1024, 256]\n",
      "[512, 1024, 512]\n",
      "[512, 1024, 1024]\n",
      "[1024, 32, 32]\n",
      "[1024, 32, 64]\n",
      "[1024, 32, 128]\n",
      "[1024, 32, 256]\n",
      "[1024, 32, 512]\n",
      "[1024, 32, 1024]\n",
      "[1024, 64, 32]\n",
      "[1024, 64, 64]\n",
      "[1024, 64, 128]\n",
      "[1024, 64, 256]\n",
      "[1024, 64, 512]\n",
      "[1024, 64, 1024]\n",
      "[1024, 128, 32]\n",
      "[1024, 128, 64]\n",
      "[1024, 128, 128]\n",
      "[1024, 128, 256]\n",
      "[1024, 128, 512]\n",
      "[1024, 128, 1024]\n",
      "[1024, 256, 32]\n",
      "[1024, 256, 64]\n",
      "[1024, 256, 128]\n",
      "[1024, 256, 256]\n",
      "[1024, 256, 512]\n",
      "[1024, 256, 1024]\n",
      "[1024, 512, 32]\n",
      "[1024, 512, 64]\n",
      "[1024, 512, 128]\n",
      "[1024, 512, 256]\n",
      "[1024, 512, 512]\n",
      "[1024, 512, 1024]\n",
      "[1024, 1024, 32]\n",
      "[1024, 1024, 64]\n",
      "[1024, 1024, 128]\n",
      "[1024, 1024, 256]\n",
      "[1024, 1024, 512]\n",
      "[1024, 1024, 1024]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "values = [32, 64, 128, 256, 512, 1024]\n",
    "combinations = list(itertools.product(values, repeat=3))\n",
    "\n",
    "print(\"Number of combinations:\", len(combinations))\n",
    "print(\"Combinations:\", combinations)\n",
    "\n",
    "for i in combinations:\n",
    "    print(list(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".DeepLCCS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
